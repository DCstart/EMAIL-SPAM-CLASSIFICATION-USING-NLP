{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n"
      ],
      "metadata": {
        "id": "KhOFlE_q8zkE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('emails.csv')\n",
        "def transform_text(text):\n",
        "text = text.lower()\n",
        "text = nltk.word_tokenize(text)\n",
        "\n",
        "y = []\n",
        "for i in text:\n",
        "if i.isalnum():\n",
        "y.append(i)\n",
        "\n",
        "text = y[:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "y.clear()\n",
        "\n",
        "for i in text:\n",
        "if i not in stopwords.words('english') and i not in string.punctuation:\n",
        "y.append(i)\n",
        "\n",
        "text = y[:]\n",
        "y.clear()\n",
        "\n",
        "for i in text:\n",
        "y.append(ps.stem(i))\n",
        "\n",
        "\n",
        "return \" \".join(y)\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def transform_text(text):\n",
        "y = []\n",
        "text = text.lower().split()\n",
        "for i in text:\n",
        "if i not in stopwords.words('english') and i not in string.punctuation:\n",
        "y.append(i)\n",
        "return ' '.join(y)\n",
        "\n",
        "# Example usage\n",
        "transformed_text = transform_text(\"I'm gonna be home soon and i don't\n",
        "want to talk about this stuff anymore tonight, k? I've cried enough\n",
        "today.\")\n",
        "print(transformed_text)\n",
        "\n",
        "\n",
        "df['text'][10]\n",
        "\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "ps.stem('loving')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df['transformed_text'] = df['text'].apply(transform_text)\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "wc =\n",
        "WordCloud(width=500,height=500,min_font_size=10,background_color='white\n",
        " ')\n",
        "\n",
        "spam_wc = wc.generate(df[df['target'] ==\n",
        "1]['transformed_text'].str.cat(sep=\" \"))\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(spam_wc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ham_wc = wc.generate(df[df['target'] ==\n",
        "0]['transformed_text'].str.cat(sep=\" \"))\n",
        "\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.imshow(ham_wc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df.head()\n",
        "\n",
        "\n",
        "spam_corpus = []\n",
        "for msg in df[df['target'] == 1]['transformed_text'].tolist():\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for word in msg.split():\n",
        "        spam_corpus.append(word)\n",
        "\n",
        "\n",
        "len(spam_corpus)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "sns.barplot(pd.DataFrame(Counter(spam_corpus).most_common(30))[0],pd.Da\n",
        " taFrame(Counter(spam_corpus).most_common(30))[1])\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "ham_corpus = []\n",
        "for msg in df[df['target'] == 0]['transformed_text'].tolist():\n",
        "    for word in msg.split():\n",
        "        ham_corpus.append(word)\n",
        "\n",
        "len(ham_corpus)\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "sns.barplot(pd.DataFrame(Counter(ham_corpus).most_common(30))[0],pd.Dat\n",
        " aFrame(Counter(ham_corpus).most_common(30))[1])\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Text Vectorization\n",
        "# using Bag of Words\n",
        "df.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r31KV7H-AjL9",
        "outputId": "d645cece-ea54-495d-95c9-fa6db424a416"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5172 entries, 0 to 5171\n",
            "Columns: 3002 entries, Email No. to Prediction\n",
            "dtypes: int64(3001), object(1)\n",
            "memory usage: 118.5+ MB\n"
          ]
        }
      ]
    }
  ]
}